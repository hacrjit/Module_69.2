{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154face4-ab51-4feb-800a-8815aea04fb2",
   "metadata": {},
   "source": [
    "### Q1. Import the Dataset and Examine the Variables\n",
    "\n",
    "1. **Importing necessary libraries and loading the dataset:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "```\n",
    "\n",
    "2. **Displaying the first few rows and the summary statistics:**\n",
    "\n",
    "```python\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Display the summary statistics\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "3. **Visualizing the distribution of variables:**\n",
    "\n",
    "```python\n",
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(df, hue='Outcome')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap to visualize correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Q2. Preprocess the Data\n",
    "\n",
    "1. **Checking and handling missing values:**\n",
    "\n",
    "```python\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# As the dataset does not have any missing values, there's no need for imputation in this case\n",
    "```\n",
    "\n",
    "2. **Removing outliers using IQR (Interquartile Range):**\n",
    "\n",
    "```python\n",
    "# Function to remove outliers\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers from numeric columns\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "for column in columns:\n",
    "    df = remove_outliers(df, column)\n",
    "```\n",
    "\n",
    "### Q3. Split the Dataset into Training and Test Sets\n",
    "\n",
    "1. **Splitting the data:**\n",
    "\n",
    "```python\n",
    "# Features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "### Q4. Train a Decision Tree Model\n",
    "\n",
    "1. **Training the model with cross-validation to optimize hyperparameters:**\n",
    "\n",
    "```python\n",
    "# Define the model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameters for grid search\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_dt = grid_search.best_estimator_\n",
    "```\n",
    "\n",
    "### Q5. Evaluate the Model\n",
    "\n",
    "1. **Predicting and evaluating the performance:**\n",
    "\n",
    "```python\n",
    "# Predictions on the test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, best_dt.predict_proba(X_test)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Q6. Interpret the Decision Tree\n",
    "\n",
    "1. **Visualizing and interpreting the decision tree:**\n",
    "\n",
    "```python\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_dt, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "2. **Identifying the most important variables:**\n",
    "\n",
    "```python\n",
    "# Feature importance\n",
    "importances = best_dt.feature_importances_\n",
    "feature_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "print(feature_importance)\n",
    "```\n",
    "\n",
    "### Q7. Validate the Model\n",
    "\n",
    "1. **Validating the model with sensitivity analysis and scenario testing:**\n",
    "\n",
    "```python\n",
    "# Sensitivity analysis\n",
    "# You can modify some test data slightly and check the predictions to see how sensitive the model is to changes\n",
    "\n",
    "# Scenario testing\n",
    "# Apply the model to a new dataset or create synthetic data to see how it performs under different scenarios\n",
    "\n",
    "# Example of modifying the test set slightly\n",
    "X_test_modified = X_test.copy()\n",
    "X_test_modified['Glucose'] += 10  # Adding 10 units to the Glucose column\n",
    "\n",
    "y_pred_modified = best_dt.predict(X_test_modified)\n",
    "print(\"Modified Prediction Results:\", classification_report(y_test, y_pred_modified))\n",
    "```\n",
    "\n",
    "By following these steps, we create, train, and evaluate a decision tree model for identifying diabetic patients. The model's performance is analyzed, and its robustness is tested through various validation methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
